{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## CNN text classification model\n",
    "\n",
    "auther: kun wu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config keras for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from keras import backend as K\n",
    "\n",
    "# with K.tf.device('/gpu:1'):\n",
    "#     config = tf.ConfigProto(intra_op_parallelism_threads=4,\\\n",
    "#            inter_op_parallelism_threads=4, allow_soft_placement=True,\\\n",
    "#            device_count = {'CPU' : 1, 'GPU' : 1})\n",
    "#     session = tf.Session(config=config)\n",
    "#     K.set_session(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>...</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>59848</td>\n",
       "      <td>0</td>\n",
       "      <td>cool like would want mother read realli great ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>59849</td>\n",
       "      <td>0</td>\n",
       "      <td>thank would make life lot less anxietyinduc ke...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>59852</td>\n",
       "      <td>0</td>\n",
       "      <td>urgent design problem kudo take impress</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>59855</td>\n",
       "      <td>0</td>\n",
       "      <td>someth ill abl instal site releas</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>59856</td>\n",
       "      <td>1</td>\n",
       "      <td>haha guy bunch loser</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.87234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id  target  \\\n",
       "0           0  59848       0   \n",
       "1           1  59849       0   \n",
       "2           2  59852       0   \n",
       "3           3  59855       0   \n",
       "4           4  59856       1   \n",
       "\n",
       "                                        comment_text  severe_toxicity  \\\n",
       "0  cool like would want mother read realli great ...         0.000000   \n",
       "1  thank would make life lot less anxietyinduc ke...         0.000000   \n",
       "2            urgent design problem kudo take impress         0.000000   \n",
       "3                  someth ill abl instal site releas         0.000000   \n",
       "4                               haha guy bunch loser         0.021277   \n",
       "\n",
       "   obscene  identity_attack   insult  threat  asian  ...  article_id  \\\n",
       "0      0.0         0.000000  0.00000     0.0    NaN  ...        2006   \n",
       "1      0.0         0.000000  0.00000     0.0    NaN  ...        2006   \n",
       "2      0.0         0.000000  0.00000     0.0    NaN  ...        2006   \n",
       "3      0.0         0.000000  0.00000     0.0    NaN  ...        2006   \n",
       "4      0.0         0.021277  0.87234     0.0    0.0  ...        2006   \n",
       "\n",
       "     rating  funny  wow  sad  likes  disagree  sexual_explicit  \\\n",
       "0  rejected      0    0    0      0         0              0.0   \n",
       "1  rejected      0    0    0      0         0              0.0   \n",
       "2  rejected      0    0    0      0         0              0.0   \n",
       "3  rejected      0    0    0      0         0              0.0   \n",
       "4  rejected      0    0    0      1         0              0.0   \n",
       "\n",
       "   identity_annotator_count  toxicity_annotator_count  \n",
       "0                         0                         4  \n",
       "1                         0                         4  \n",
       "2                         0                         4  \n",
       "3                         0                         4  \n",
       "4                         4                        47  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "BASE_DIR = '/home/kwu14/data/cs584_course_project/'\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(BASE_DIR, 'preprocessed_train.csv'))\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df['comment_text'].astype(str).values\n",
    "y_train = train_df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/kwu14/anaconda3/envs/p37-nlp/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kwu14/anaconda3/envs/p37-nlp/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kwu14/anaconda3/envs/p37-nlp/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kwu14/anaconda3/envs/p37-nlp/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kwu14/anaconda3/envs/p37-nlp/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kwu14/anaconda3/envs/p37-nlp/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/kwu14/anaconda3/envs/p37-nlp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kwu14/anaconda3/envs/p37-nlp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kwu14/anaconda3/envs/p37-nlp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kwu14/anaconda3/envs/p37-nlp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kwu14/anaconda3/envs/p37-nlp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kwu14/anaconda3/envs/p37-nlp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 392342, max length in the text is 305\n",
      "CPU times: user 2min 14s, sys: 984 ms, total: 2min 15s\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from keras.preprocessing import text\n",
    "\n",
    "tk = text.Tokenizer()\n",
    "tk.fit_on_texts(x_train)\n",
    "x_train = tk.texts_to_sequences(x_train)\n",
    "\n",
    "vocab_size = len(tk.word_index)\n",
    "max_len = 0\n",
    "for tokens in x_train:\n",
    "    max_len = len(tokens) if len(tokens) > max_len else max_len\n",
    "\n",
    "print(f'vocabulary size: {vocab_size}, max length in the text is {max_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glovevectorizer import generate_weights, load_glove_weights\n",
    "\n",
    "path = os.path.join(BASE_DIR, 'glove.6B.300d.txt')\n",
    "glove_weights = load_glove_weights(path)\n",
    "weights = generate_weights(glove_weights, word2idx=tk.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     (None, 305)               0         \n",
      "_________________________________________________________________\n",
      "embedding_layer (Embedding)  (None, 305, 300)          117702900 \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 301, 128)          192128    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 60, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 56, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 7, 128)            82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 118,075,765\n",
      "Trainable params: 372,865\n",
      "Non-trainable params: 117,702,900\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kwu14/anaconda3/envs/p37-nlp/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv1D, MaxPooling1D, Embedding, Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "embedding_size = 300\n",
    "\n",
    "words = Input(shape=(max_len, ), name='input_layer')\n",
    "x = Embedding(vocab_size + 1, embedding_size, weights=[weights], trainable=False, name='embedding_layer')(words)\n",
    "l_cov1= Conv1D(128, 5, activation='relu')(x)\n",
    "l_pool1 = MaxPooling1D(5)(l_cov1)\n",
    "l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1)\n",
    "l_pool2 = MaxPooling1D(5)(l_cov2)\n",
    "l_cov3 = Conv1D(128, 5, activation='relu')(l_pool2)\n",
    "l_pool3 = MaxPooling1D(5)(l_cov3)  # global max pooling\n",
    "l_flat = Flatten()(l_pool3)\n",
    "l_dense = Dense(128, activation='relu')(l_flat)\n",
    "out = Dense(1, activation='sigmoid')(l_dense)\n",
    "\n",
    "model = Model(input=words, output=out)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1443899 samples, validate on 360975 samples\n",
      "Epoch 1/10\n",
      "1443899/1443899 [==============================] - 71s 49us/step - loss: 0.2150 - acc: 0.9425 - val_loss: 0.2343 - val_acc: 0.9370\n",
      "Epoch 2/10\n",
      "1443899/1443899 [==============================] - 71s 49us/step - loss: 0.2117 - acc: 0.9433 - val_loss: 0.2391 - val_acc: 0.9368\n",
      "Epoch 3/10\n",
      " 307200/1443899 [=====>........................] - ETA: 49s - loss: 0.2073 - acc: 0.9445"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 1024\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train, \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs, \n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
